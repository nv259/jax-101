{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.scipy.special import logsumexp\n",
        "from jax import jit, vmap, pmap, grad\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "cGvkr0TaR7pU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP training on MNIST"
      ],
      "metadata": {
        "id": "nHjeQAbfQh9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtDcyQ-wP0Ic"
      },
      "outputs": [],
      "source": [
        "# TODO: init MLP and add the predict\n",
        "# TODO: add data loading in PyTorch\n",
        "# TODO: ad the training loop, loss fn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "mnist_img_size = (28, 28)\n",
        "batch_size = 128\n",
        "\n",
        "def init_MLP(layer_widths, rng_key, scale=0.01):\n",
        "\n",
        "    params = []\n",
        "    keys = jax.random.split(rng_key, num=len(layer_widths)-1)\n",
        "\n",
        "    for in_width, out_width, key in zip(layer_widths[:-1], layer_widths[1:], keys):\n",
        "        weight_key, bias_key = jax.random.split(key)\n",
        "\n",
        "        params.append([\n",
        "            scale * jax.random.normal(weight_key, (out_width, in_width)),    # weight\n",
        "            scale * jax.random.normal(bias_key, (out_width,))                 # bias\n",
        "        ])\n",
        "\n",
        "    return params\n",
        "\n",
        "# tests\n",
        "key = jax.random.PRNGKey(0)\n",
        "MLP_params = init_MLP([784, 512, 256, 10], key)\n",
        "\n",
        "print(jax.tree.map(lambda x: x.shape, MLP_params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF6uPVLHQ6-U",
        "outputId": "9dfcc9a8-a6c2-4d60-98b5-f840c9ee856f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(512, 784), (512,)], [(256, 512), (256,)], [(10, 256), (10,)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_predict(params, x):\n",
        "    hidden_layers = params[:-1]\n",
        "\n",
        "    for w, b in hidden_layers:\n",
        "        x = jnp.dot(w, x) + b\n",
        "        x = jax.nn.relu(x)\n",
        "\n",
        "    w_final, b_final = params[-1]\n",
        "    logits = jnp.dot(w_final, x) + b_final\n",
        "    return logits - logsumexp(logits)\n",
        "\n",
        "# tests\n",
        "dummy_img_flat = np.random.randn(np.prod(mnist_img_size))\n",
        "print(dummy_img_flat.shape)\n",
        "\n",
        "predict = jax.jit(MLP_predict)\n",
        "print(predict(MLP_params, dummy_img_flat).shape)\n",
        "\n",
        "batched_MLP_predict = jit(vmap(MLP_predict, in_axes=(None, 0)))\n",
        "print(batched_MLP_predict(MLP_params, np.stack([dummy_img_flat, dummy_img_flat])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxX_otSoT0KK",
        "outputId": "4081730a-b45f-4093-d592-a609933a0f09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784,)\n",
            "(10,)\n",
            "(2, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_transform(img):\n",
        "    img = np.array(img, dtype=np.float32).reshape(-1)\n",
        "\n",
        "    return img\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    transposed_data = list(zip(*batch))\n",
        "\n",
        "    images = np.stack(transposed_data[0])\n",
        "    labels = np.array(transposed_data[1])\n",
        "\n",
        "    return (images, labels)\n",
        "\n",
        "\n",
        "train_dataset = MNIST(root='./train_mnist', train=True, download=True, transform=custom_transform)\n",
        "test_dataset = MNIST(root='./test_mnist', train=False, download=True, transform=custom_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "batch_data = next(iter(train_loader))\n",
        "print(batch_data[0].shape)  # images shape\n",
        "print(batch_data[1].shape)  # labels shape\n",
        "print(type(batch_data[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqoA1ZxCarIh",
        "outputId": "4e44ed57-271e-4260-8b55-ac3901321dd9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 784)\n",
            "(128,)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizations"
      ],
      "metadata": {
        "id": "FCpkSJdMQkUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: visualize the MLP weight\n",
        "# TODO: visualize embeddings using t-SNE\n",
        "# TODO: dead neurons"
      ],
      "metadata": {
        "id": "6sHXh9vSQlsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallelization"
      ],
      "metadata": {
        "id": "09o7NLAXQmF8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYvARQVBQnkD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}