{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**From Haiku documentation**"
      ],
      "metadata": {
        "id": "QqnrjlnPHX66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw5KYXdUC61Y",
        "outputId": "460d2111-a726-4ecb-f151-967f0b6df3c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-bb0j1585\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/dm-haiku /tmp/pip-req-build-bb0j1585\n",
            "  Resolved https://github.com/deepmind/dm-haiku to commit a7b7e73dae840153ecd828e97a64b6a875b168f7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.13.dev0) (1.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku==0.0.13.dev0)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.13.dev0) (1.25.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.13.dev0) (0.9.0)\n",
            "Building wheels for collected packages: dm-haiku\n",
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-haiku: filename=dm_haiku-0.0.13.dev0-py3-none-any.whl size=373915 sha256=5717c5aab50a0c52ea8e142bc7faa4bce03fa180efde8b8ccf70c60d47911f47\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jtz30r4p/wheels/b1/df/f1/a357fa8f00c36052bdae1e1fd363650c0bd1e8c3959487b6fb\n",
            "Successfully built dm-haiku\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.13.dev0 jmp-0.0.4\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/deepmind/dm-haiku"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Haiku Basics"
      ],
      "metadata": {
        "id": "E10U68qGDWaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "331aWAZHDRGG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A first example with `hk.transform`\n",
        "\n",
        " A linear module with weights and biases with custom initializations."
      ],
      "metadata": {
        "id": "1l-ni024Dht1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define module"
      ],
      "metadata": {
        "id": "7wddTXI6FSpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear1(hk.Module):\n",
        "\n",
        "    def __init__(self, output_size, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, x):\n",
        "        j, k = x.shape[-1], self.output_size\n",
        "        w_init = hk.initializers.TruncatedNormal(1. / np.sqrt(j))\n",
        "        w = hk.get_parameter(\"w\", shape=[j, k], dtype=x.dtype, init=w_init)\n",
        "        b = hk.get_parameter(\"b\", shape=[k], dtype=x.dtype, init=jnp.ones)\n",
        "\n",
        "        return jnp.dot(x, w) + b"
      ],
      "metadata": {
        "id": "_osb4JWADVAL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pure function transformation"
      ],
      "metadata": {
        "id": "jVd6E64CFXtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _forward_fn_linear1(x):\n",
        "    module = MyLinear1(output_size=2)\n",
        "    return module(x)\n",
        "\n",
        "forward_linear1 = hk.transform(_forward_fn_linear1)"
      ],
      "metadata": {
        "id": "A_x8nBTpE5lR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the forward wrapper object now contains two methods, `init` and `apply`, that are used to initialize the variables and do forward inference on the module.\n"
      ],
      "metadata": {
        "id": "M4Pa86PxFFzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forward_linear1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDiykZOcE6fy",
        "outputId": "d74bc868-44ad-453a-9bf4-09ecaa0249a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformed(init=<function without_state.<locals>.init_fn at 0x7cf8241d9cf0>, apply=<function without_state.<locals>.apply_fn at 0x7cf8241d9c60>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Init` fn\n",
        "Calling the init method will initialize the parameters of the network and return them. The init method takes a `jax.random.PRNGKey` and a sample input (usually just some dummy values to tell the networks about the expected shapes).\n"
      ],
      "metadata": {
        "id": "MqmoqkT_FeH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = jnp.array([[1., 2., 3.]])\n",
        "rng_key = jax.random.PRNGKey(42)\n",
        "\n",
        "params = forward_linear1.init(rng=rng_key, x=dummy_x)\n",
        "print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leewfELBFuHb",
        "outputId": "6c86bd87-b29c-402a-fdeb-61aae28fa9a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'my_linear1': {'w': Array([[-0.30350363,  0.5123802 ],\n",
            "       [ 0.08009142, -0.3163005 ],\n",
            "       [ 0.6056666 ,  0.5820702 ]], dtype=float32), 'b': Array([1., 1.], dtype=float32)}}\n",
            "(1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `apply` fn\n",
        "use the params to apply the forward function to some inputs."
      ],
      "metadata": {
        "id": "UoXJG-rHGNSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_x = jnp.array([[1., 2., 3.]])\n",
        "sample_x_2 = jnp.array([[4., 5., 6.],\n",
        "                        [7., 8., 9.]])\n",
        "\n",
        "output1 = forward_linear1.apply(params=params, x=sample_x, rng=rng_key)\n",
        "# Outputs are identical for given inputs since the forward inference is non-stochastic.\n",
        "output2 = forward_linear1.apply(params=params, x=sample_x, rng=rng_key)\n",
        "\n",
        "output3 = forward_linear1.apply(params=params, x=sample_x_2, rng=rng_key)\n",
        "\n",
        "print(output1)\n",
        "print(output2)  # same as ouptut1\n",
        "print(output3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbhpYbv1F7f2",
        "outputId": "85983786-40c9-4bf9-ca37-5af67cff5249"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.6736789 2.6259897]]\n",
            "[[2.6736789 2.6259897]]\n",
            "[[3.820442 4.960439]\n",
            " [4.967205 7.294889]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference without random key\n",
        "In some cases, the module that we built is inherently non-stochastic. Hence, passing a random key to apply method seems redundant. Haiku offers another transformation `hk.without_apply_rng` which can be further wrapped around our `hk.transform` method."
      ],
      "metadata": {
        "id": "egrnyMtLHfql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forward_without_rng = hk.without_apply_rng(hk.transform(_forward_fn_linear1))\n",
        "\n",
        "params = forward_without_rng.init(rng=rng_key, x=sample_x)\n",
        "output = forward_without_rng.apply(params=params, x=sample_x)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcx7BULzHDUU",
        "outputId": "9f6e5543-f95c-4911-b01d-b16e26ee986c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.6736789 2.6259897]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also mutate the parameters and then do forward inference to generate a different output for the same inputs. This is what is done to apply gradient descent to our parameters while learning."
      ],
      "metadata": {
        "id": "cNfGnDwAIidv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mutated_params = jax.tree_util.tree_map(lambda x: x+1., params)\n",
        "print(f'Mutated params \\n : {mutated_params}')\n",
        "mutated_output = forward_without_rng.apply(x=sample_x, params=mutated_params)\n",
        "print(f'Output with mutated params \\n {mutated_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R64jBIDtIirh",
        "outputId": "fa42b8e7-419c-444a-eb19-5b53545ac7e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutated params \n",
            " : {'my_linear1': {'b': Array([2., 2.], dtype=float32), 'w': Array([[0.69649637, 1.5123801 ],\n",
            "       [1.0800915 , 0.6836995 ],\n",
            "       [1.6056666 , 1.5820701 ]], dtype=float32)}}\n",
            "Output with mutated params \n",
            " [[9.673679 9.62599 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stateful Inference in Haiku\n",
        "For some modules you might want to maintain and carry over the internal state across function calls."
      ],
      "metadata": {
        "id": "Yx2kE-OlMMu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stateful_f(x):\n",
        "    counter = hk.get_state(\"counter\", shape=[], dtype=jnp.int32, init=jnp.ones)\n",
        "    multiplier = hk.get_parameter(\"multiplier\", shape=[1, ], dtype=x.dtype, init=jnp.ones)\n",
        "    hk.set_state(\"counter\", counter + 1)\n",
        "    output = x + multiplier * counter\n",
        "\n",
        "    return output\n",
        "\n",
        "stateful_forward = hk.without_apply_rng(hk.transform_with_state(stateful_f))\n",
        "sample_x = jnp.array([[5., ]])\n",
        "params, state = stateful_forward.init(x=sample_x, rng=rng_key)\n",
        "\n",
        "print(f'Initial params:\\n{params}\\nInitial state:\\n{state}')\n",
        "print('##########')\n",
        "for i in range(3):\n",
        "  output, state = stateful_forward.apply(params, state, x=sample_x)\n",
        "  print(f'After {i+1} iterations:\\nOutput: {output}\\nState: {state}')\n",
        "  print('##########')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaS2nlL-Ik_v",
        "outputId": "9eef00c1-eaeb-4df7-bed4-51e8d64bbfaa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial params:\n",
            "{'~': {'multiplier': Array([1.], dtype=float32)}}\n",
            "Initial state:\n",
            "{'~': {'counter': Array(1, dtype=int32)}}\n",
            "##########\n",
            "After 1 iterations:\n",
            "Output: [[6.]]\n",
            "State: {'~': {'counter': Array(2, dtype=int32)}}\n",
            "##########\n",
            "After 2 iterations:\n",
            "Output: [[7.]]\n",
            "State: {'~': {'counter': Array(3, dtype=int32)}}\n",
            "##########\n",
            "After 3 iterations:\n",
            "Output: [[8.]]\n",
            "State: {'~': {'counter': Array(4, dtype=int32)}}\n",
            "##########\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Built-in Haiku nets and nested modules"
      ],
      "metadata": {
        "id": "GcLFUExjNnT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModuleCustom(hk.Module):\n",
        "\n",
        "    def __init__(self, output_size=2, name='custom_linear'):\n",
        "        super().__init__(name=name)\n",
        "        self._internal_linear_1 = hk.nets.MLP(output_sizes=[2, 3], name='hk_internal_linear')\n",
        "        self._internal_linear_2 = MyLinear1(output_size=output_size, name='old_linear')\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self._internal_linear_1(x)\n",
        "        x = self._internal_linear_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def _custom_forward_fn(x):\n",
        "    module = MyModuleCustom()\n",
        "\n",
        "    return module(x)"
      ],
      "metadata": {
        "id": "f8v7KaWoNPwf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_forward_without_rng = hk.without_apply_rng(hk.transform(_custom_forward_fn))\n",
        "params = custom_forward_without_rng.init(rng=rng_key, x=sample_x)\n",
        "print(jax.tree.map(lambda x: x.shape, params))\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRsEBXmUOe46",
        "outputId": "71272039-d438-4d02-8f54-f02f254ce622"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'custom_linear/~/hk_internal_linear/~/linear_0': {'b': (2,), 'w': (1, 2)}, 'custom_linear/~/hk_internal_linear/~/linear_1': {'b': (3,), 'w': (2, 3)}, 'custom_linear/~/old_linear': {'b': (2,), 'w': (3, 2)}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'custom_linear/~/hk_internal_linear/~/linear_0': {'w': Array([[ 1.51595   , -0.23353337]], dtype=float32),\n",
              "  'b': Array([0., 0.], dtype=float32)},\n",
              " 'custom_linear/~/hk_internal_linear/~/linear_1': {'w': Array([[-0.22075887, -0.27375957,  0.5931483 ],\n",
              "         [ 0.7818068 ,  0.72626334, -0.6860752 ]], dtype=float32),\n",
              "  'b': Array([0., 0., 0.], dtype=float32)},\n",
              " 'custom_linear/~/old_linear': {'w': Array([[ 0.28584382,  0.31626168],\n",
              "         [ 0.2335775 , -0.4827032 ],\n",
              "         [-0.14647584, -0.7185701 ]], dtype=float32),\n",
              "  'b': Array([1., 1.], dtype=float32)}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNG Keys with `hk.next_rng_key()`"
      ],
      "metadata": {
        "id": "gcALIW3GSyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HkRandom2(hk.Module):\n",
        "\n",
        "    def __init__(self, rate=0.5):\n",
        "        super().__init__()\n",
        "        self.rate = rate\n",
        "\n",
        "    def __call__(self, x):\n",
        "        key1 = hk.next_rng_key()\n",
        "        return jax.random.bernoulli(key1, 1.0 - self.rate, shape=x.shape)\n",
        "\n",
        "\n",
        "class HkRandomNest(hk.Module):\n",
        "\n",
        "    def __init__(self, rate=0.5):\n",
        "        super().__init__()\n",
        "        self.rate = rate\n",
        "        self._another_random_module = HkRandom2()\n",
        "\n",
        "    def __call__(self, x):\n",
        "        key2 = hk.next_rng_key()\n",
        "        p1 = self._another_random_module(x)\n",
        "        p2 = jax.random.bernoulli(key2, 1.0 - self.rate, shape=x.shape)\n",
        "\n",
        "        print(f\"Bernoullis are: {p1, p2}\")\n",
        "\n",
        "# Note that the modules that are stochastic cannot be wrapped with hk.without_apply_rng()\n",
        "forward = hk.transform(lambda x: HkRandomNest()(x))\n",
        "\n",
        "x = jnp.array(1.)\n",
        "print(\"INIT:\")\n",
        "params = forward.init(rng_key, x=x)\n",
        "print(\"APPLY:\")\n",
        "prediction = forward.apply(params, x=x, rng=rng_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V57DbdSsOwGz",
        "outputId": "33756c90-0a06-4875-e763-4fbbea7e6ebc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INIT:\n",
            "Bernoullis are: (Array(True, dtype=bool), Array(False, dtype=bool))\n",
            "APPLY:\n",
            "Bernoullis are: (Array(True, dtype=bool), Array(False, dtype=bool))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note that this means that passing the same random key to multiple calls of the apply function will generate the same stochastic results!**"
      ],
      "metadata": {
        "id": "UnhsO-tcUhBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "  forward.apply(params, x=x, rng=rng_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5NUmeiwUfei",
        "outputId": "c740a45b-10c2-4fb0-e359-7089278fab15"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoullis are: (Array(True, dtype=bool), Array(False, dtype=bool))\n",
            "Bernoullis are: (Array(True, dtype=bool), Array(False, dtype=bool))\n",
            "Bernoullis are: (Array(True, dtype=bool), Array(False, dtype=bool))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# solution 1:\n",
        "for _ in range(3):\n",
        "  rng_key, apply_rng_key = jax.random.split(rng_key)\n",
        "  forward.apply(params, x=x, rng=apply_rng_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tir7auarUmxU",
        "outputId": "6b0bbb8c-31b5-40cb-e239-1d7b4886a458"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoullis are: (Array(False, dtype=bool), Array(False, dtype=bool))\n",
            "Bernoullis are: (Array(True, dtype=bool), Array(False, dtype=bool))\n",
            "Bernoullis are: (Array(False, dtype=bool), Array(False, dtype=bool))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# solution 2:\n",
        "rng_sequence = hk.PRNGSequence(rng_key)\n",
        "for _ in range(3):\n",
        "  forward.apply(params, x=x, rng=next(rng_sequence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZsyLXGWUokZ",
        "outputId": "cbb729fe-24f0-4e00-e6c9-8be1cf75f52b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoullis are: (Array(False, dtype=bool), Array(True, dtype=bool))\n",
            "Bernoullis are: (Array(False, dtype=bool), Array(False, dtype=bool))\n",
            "Bernoullis are: (Array(False, dtype=bool), Array(True, dtype=bool))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limitations of Nesting JAX Functions and Haiku Modules\n",
        "\n",
        "A JAX transform inside of a hk.transform is likely to transform a side effecting function, which will result in an `UnexpectedTracerError`. This page describes two ways to get around this."
      ],
      "metadata": {
        "id": "prbvBRFJWIgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once a Haiku network has been transformed to a pair of pure functions using hk.transform, it’s possible to freely combine these with any JAX transformations like `jax.jit`, `jax.grad`, `jax.lax.scan` and so on."
      ],
      "metadata": {
        "id": "zuKxxjpuWgiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "def net(x): # inside of a hk.transform, this is still side-effecting\n",
        "    w = hk.get_parameter(\"w\", (2, 2), init=jnp.ones)\n",
        "\n",
        "    return w @ x\n",
        "\n",
        "def eval_shape_net(x):\n",
        "    output_shape = jax.eval_shape(net, x)   # eval_shape on side-effecting function\n",
        "    return net(x)\n",
        "\n",
        "init, _ = hk.transform(eval_shape_net)\n",
        "\n",
        "try:\n",
        "    init(jax.random.PRNGKey(0), jnp.ones((2, 2)))\n",
        "except jax.errors.UnexpectedTracerError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkOhm7wdWNC_",
        "outputId": "f2314e8c-d08e-4d5f-ee88-0e7f779b1fc4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An UnexpectedTracerError was raised while inside a Haiku transformed function (see error above).\n",
            "Hint: are you using a JAX transform or JAX control-flow function (jax.vmap/jax.lax.scan/...) inside a Haiku transform? You might want to use the Haiku version of the transform instead (hk.vmap/hk.scan/...).\n",
            "See https://dm-haiku.readthedocs.io/en/latest/notebooks/transforms.html on why you can't use JAX transforms inside a Haiku module.\n",
            "See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.UnexpectedTracerError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# solution\n",
        "def net(w, x):\n",
        "    return w @ x\n",
        "\n",
        "def eval_shape_net(x):\n",
        "    w = hk.get_parameter(\"w\", (3, 2), init=jnp.ones)\n",
        "    output_shape = jax.eval_shape(net, w, x)\n",
        "    return net(w, x)\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "x = jnp.ones((2, 3))\n",
        "init, apply = hk.transform(eval_shape_net)\n",
        "params = init(key, x=x)\n",
        "apply(params, key, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ARzTqAZXggV",
        "outputId": "890c200b-edec-4aed-d3bf-0c6f6783b7b8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# however\n",
        "def eval_shape_net(x):\n",
        "    net = hk.nets.MLP([300, 100])\n",
        "    output_shape = jax.eval_shape(net, x)\n",
        "    return output_shape, net(x)\n",
        "\n",
        "init, _ = hk.transform(eval_shape_net)\n",
        "\n",
        "try:\n",
        "    init(jax.random.PRNGKey(0), jnp.ones((2, 2)))\n",
        "except jax.errors.UnexpectedTracerError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "DAP7WAqiZBIX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `hk.lift`\n",
        "\n"
      ],
      "metadata": {
        "id": "Tt1PlMcwaVf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_shape_net(x):\n",
        "    net = hk.nets.MLP([300, 100])       # still side-effecting\n",
        "    init, apply = hk.transform(net)     # nested transform\n",
        "    params = hk.lift(init, name=\"inner\")(hk.next_rng_key(), x)    # register params in outer module scope with name \"inner\"\n",
        "\n",
        "    output_shape = jax.eval_shape(apply, params, hk.next_rng_key(), x)  # apply is a functionaly pure function and can be transformed!\n",
        "    out = net(x)\n",
        "\n",
        "    return out, output_shape\n",
        "\n",
        "x = jnp.ones((100, 100))\n",
        "\n",
        "init, apply = hk.transform(eval_shape_net)\n",
        "params = init(jax.random.PRNGKey(0), x=x)\n",
        "apply(params, jax.random.PRNGKey(0), x)\n",
        "\n",
        "jax.tree.map(lambda x: x.shape, params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahd20IvAaW6S",
        "outputId": "dd81de5c-4403-4b34-b85f-eeeaf726ee5c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inner/mlp/~/linear_0': {'b': (300,), 'w': (100, 300)},\n",
              " 'inner/mlp/~/linear_1': {'b': (100,), 'w': (300, 100)},\n",
              " 'mlp/~/linear_0': {'b': (300,), 'w': (100, 300)},\n",
              " 'mlp/~/linear_1': {'b': (100,), 'w': (300, 100)}}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Haiku versions of JAX transforms"
      ],
      "metadata": {
        "id": "VQ1ZHm7PceXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_shape_net(x):\n",
        "    net = hk.nets.MLP([300, 100])\n",
        "    output_shape = hk.eval_shape(net, x)\n",
        "    out = net(x)\n",
        "\n",
        "    return out, output_shape\n",
        "\n",
        "init, apply = hk.transform(eval_shape_net)\n",
        "params = init(jax.random.PRNGKey(777), jnp.ones((100, 100)))\n",
        "out = apply(params, jax.random.PRNGKey(777), jnp.ones((100, 100)))"
      ],
      "metadata": {
        "id": "dqYUSgBdcYi-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5fCqYuzcwrV",
        "outputId": "59afb355-9a3e-4ea7-8f7e-3845a0a4180e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ShapeDtypeStruct(shape=(100, 100), dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_get_parameter_fn():\n",
        "    w1 = hk.get_parameter(\"w\", [], init=jnp.zeros)\n",
        "    w2 = hk.get_parameter(\"w\", [], init=jnp.zeros)\n",
        "\n",
        "    if w1 is w2:\n",
        "        print(\"w1 is w2\")\n",
        "\n",
        "    return 0\n",
        "\n",
        "test_get_parameter = hk.transform(test_get_parameter_fn)\n",
        "params = test_get_parameter.init(jax.random.PRNGKey(0))\n",
        "print(jax.tree.map(lambda x: x.shape, params))\n",
        "test_get_parameter.apply(rng=jax.random.PRNGKey(0), params=params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoRyrCVfbcU",
        "outputId": "4975071b-6702-475f-e07b-bce88055df20"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1 is w2\n",
            "{'~': {'w': ()}}\n",
            "w1 is w2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flax Interop"
      ],
      "metadata": {
        "id": "7Fjb8EUij5ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flax inside Haiku\n",
        "```python\n",
        "haiku.experimental.flax.lift(mod, *, name)\n",
        "```\n",
        "\n",
        "Lifts a flax `nn.Module` into a Haiku transformed function.\n",
        "\n",
        "For a Flax Module (e.g. `mod = nn.Dense(10)`), `mod = lift(mod)` allows you to run the call method of the module as if the module was a regular Haiku module.\n",
        "\n",
        "Parameters and state from the Flax module are registered with Haiku and become part of the params/state dictionaries (as returned from `init`/`apply`).\n"
      ],
      "metadata": {
        "id": "AgsUDkpwkB71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flax\n",
        "from transformers import BertConfig, BertModel, FlaxAutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "tkszB2w1k7bv"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "UmScmZJPmx4U"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(tokens, pretrained_path=\"bert-base-uncased\"):\n",
        "    # Create and \"lift\" a Flax module\n",
        "    pretrained_model = hk.experimental.flax.lift(FlaxAutoModel.from_pretrained(pretrained_path), name='bert')\n",
        "    embeddings = pretrained_model(*tokens)\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "PyWCkAUZkRd-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = FlaxAutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "embeddings = pretrained_model(**tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWIEhXAGrLqF",
        "outputId": "8c6e694d-8102-4003-9346-e03f445eeded"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('pooler', 'dense', 'kernel'), ('pooler', 'dense', 'bias')}\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hZjB5E_r9me",
        "outputId": "d06ad797-c45c-4742-e531-bc850a307032"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load pretrained_model from \"bert-base-uncased\" then convert to haiku module\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import flax\n",
        "from transformers import BertConfig, BertModel, FlaxAutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "def f(tokens, pretrained_path=\"bert-base-uncased\"):\n",
        "    # Create and \"lift\" a Flax module\n",
        "    pretrained_model = hk.experimental.flax.lift(FlaxAutoModel.from_pretrained(pretrained_path), name='bert')\n",
        "    embeddings = pretrained_model(*tokens)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "pretrained_model = FlaxAutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "# haiku_module = hk.experimental.flax.lift(pretrained_model, name='bert')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZtLt_bcrQIv",
        "outputId": "f780ad8a-9d33-4bf6-9e25-36ae34ad3fab"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('pooler', 'dense', 'kernel'), ('pooler', 'dense', 'bias')}\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"I am a student at UIT.\"]\n",
        "tokens = tokenizer(sentences, return_tensors='jax')\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNsKZb-ekBhV",
        "outputId": "871805d1-1dfc-480b-ab6f-ffe8e8ad252b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': Array([[  101,  1045,  2572,  1037,  3076,  2012, 21318,  2102,  1012,\n",
              "          102]], dtype=int32), 'token_type_ids': Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), 'attention_mask': Array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLZ4aWhtt9hk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}